{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Seedlings Classification - Tensorflow Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "import glob\n",
    "from IPython.display import Image as img\n",
    "from PIL import Image\n",
    "import cv2\n",
    "#https://gist.github.com/eerwitt/518b0c9564e500b4b50f\n",
    "#https://www.kaggle.com/gimunu/data-augmentation-with-keras-into-cnn\n",
    "#https://www.kaggle.com/lextoumbourou/humpback-whale-id-data-and-aug-exploration\n",
    "#https://www.youtube.com/watch?v=ViO56ASqeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - One Hot labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black-grass' 'Charlock' 'Cleavers' 'Common Chickweed' 'Common wheat'\n",
      " 'Fat Hen' 'Loose Silky-bent' 'Maize' 'Scentless Mayweed' 'Shepherds Purse'\n",
      " 'Small-flowered Cranesbill' 'Sugar beet'] \n",
      "\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "dirs = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n",
    "       'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n",
    "values = np.array(dirs)\n",
    "print(values,'\\n')\n",
    "\n",
    "#transformando em one hot\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encodeded = np.array(onehot_encoder.fit_transform(integer_encoded)).astype(int)\n",
    "print(onehot_encodeded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = '../data/SeedlingData/train/'\n",
    "training_data = []\n",
    "__ = -1;\n",
    "for img_class in dirs:\n",
    "    __ += 1\n",
    "    _=0;\n",
    "    for filename in glob.glob(training_path+img_class+'/*.png'):\n",
    "        im = cv2.imread(filename, 0)\n",
    "        im = cv2.resize(im, IMG_SIZE)\n",
    "        training_data.append([im, onehot_encodeded[__]])\n",
    "#         if _==0:\n",
    "#             display(img(filename, width=80, height=80))\n",
    "#             print(filename)\n",
    "#             print(onehot_encodeded[__])\n",
    "#         _+= 1\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../data/SeedlingData/test/'\n",
    "test_data = []\n",
    "for filename in glob.glob(test_path+'/*.png'):\n",
    "    im = cv2.imread(filename)\n",
    "    im = cv2.resize(im, IMG_SIZE)\n",
    "    test_data.append(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides = [1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x_image, shape=[5,5,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling, shape=[5,5,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1, 7*7*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-123835b78a48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mrand_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "        rand_ind = np.random.randint(len(training_data), size=10)\n",
    "        feed = {x:training_data[rand_ind][0], y_:training_data[rand_ind][1]}\n",
    "        sess.run(train, feed_dict = feed)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print('ON STEP: {}'.format(i))\n",
    "            print('ACCURACY: ')\n",
    "            matches = tf.equal(tf.argmax(y_, 1), tf.argmax(y_, 1))\n",
    "            acc = tf.reduce_mean(tf.cast(matchs, tf.float32))\n",
    "            print(sess.run(acc, feed_dict = feed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7bc0646780>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7bc067d7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(image_list[random.randrange(0, 1000)])\n",
    "# print(image_list[random.randrange(0, 1000)])\n",
    "plt.imshow(training_data[random.randrange(0,4000)][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(label_list[random.randrange(0,4000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
